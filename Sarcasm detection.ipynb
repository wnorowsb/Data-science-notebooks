{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarcasm headline detection\n",
    "### Author: Bartosz Wnorowski\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Purpose of this notebook is to create machine learning model to classify a headline to be sarcastic or not. All of the work is based on a given dataset.\n",
    "\n",
    "We will start with getting a closer look at the dataframe. After that, if there will be a need for some data cleaning and processing we will do this to ensure better model's quality. And finally, we will create classification model with methods that suit our case best. \n",
    "\n",
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn import naive_bayes, svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('HEADLINES.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  is_sarcastic\n",
       "0  former versace store clerk sues over secret 'b...             0\n",
       "1  the 'roseanne' revival catches up to our thorn...             0\n",
       "2  mom starting to fear son's web series closest ...             1\n",
       "3  boehner just wants wife to listen, not come up...             1\n",
       "4  j.k. rowling wishes snape happy birthday in th...             0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset consists of 2 columns, headline text and boolean is_sarcastic value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>26709.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.438953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.496269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       is_sarcastic\n",
       "count  26709.000000\n",
       "mean       0.438953\n",
       "std        0.496269\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is nearly equal amount of sarcastic and non-sarcastic headlines in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26709 entries, 0 to 26708\n",
      "Data columns (total 2 columns):\n",
      "headline        26709 non-null object\n",
      "is_sarcastic    26709 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 417.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that dataset does not contain any empty cells. That means we can move forward to prepare text to be 'edible' by some statistical model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "def clean(text, stemmer):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = [stemmer.stem(word) for word in text.split()]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "df['headline'] = df['headline'].apply(clean, args = (ps,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have cleaned our data in two steps: \n",
    "1. All special characters and digits are removed.\n",
    "2. All words are replaced by theirs stems, for example verbs in different tenses has the same     reprezentation.\n",
    "\n",
    "It came out that converting leters to lowercase has negative impact on our models' quality.\n",
    "\n",
    "This actions will reduce the number of features and help with model's generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(df['headline'], df['is_sarcastic'])\n",
    "vectorizer = TfidfVectorizer(stop_words = ['english'], ngram_range=(1,3))\n",
    "Xtrain = vectorizer.fit_transform(Xtrain)\n",
    "Xtest = vectorizer.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In vectorization- step that transforms text to vactors of features we use Tf-idf. This solution will help us to reduce the impact of most common words. We also increased default ngram_range to (1,3) to express better meaning of the whole sentences.\n",
    "\n",
    "Parameters of vectorizer was experimentally choosen to get the best possible training score results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation\n",
    "\n",
    "We will try Multinominal Naive Bayes and Support Vector Machine methods for our classification and check which of them better suits for this problem. Main comparative cryterion will be F1 score (harmonic mean of precision and recall) on testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9837322798047874\n",
      "Test score: 0.7029430446749947\n"
     ]
    }
   ],
   "source": [
    "modelNB = naive_bayes.MultinomialNB()\n",
    "modelNB.fit(Xtrain, Ytrain)\n",
    "\n",
    "trainPred = modelNB.predict(Xtrain)\n",
    "testPred = modelNB.predict(Xtest)\n",
    "\n",
    "trainScore = f1_score(Ytrain,trainPred)\n",
    "testScore = f1_score(Ytest,testPred)\n",
    "\n",
    "print(\"Train score: \" + str(trainScore))\n",
    "print(\"Test score: \" + str(testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9946131805157593\n",
      "Test score: 0.8342954159592529\n"
     ]
    }
   ],
   "source": [
    "modelSVM = svm.SVC(kernel=\"linear\", C=1.0)\n",
    "modelSVM.fit(Xtrain, Ytrain)\n",
    "\n",
    "trainPred = modelSVM.predict(Xtrain)\n",
    "testPred = modelSVM.predict(Xtest)\n",
    "\n",
    "trainScore = f1_score(Ytrain,trainPred)\n",
    "testScore = f1_score(Ytest,testPred)\n",
    "\n",
    "print(\"Train score: \" + str(trainScore))\n",
    "print(\"Test score: \" + str(testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We have managed to create text classifier of a decent quality. SMV classifier with linear kernel reached 0.834 testing F1 score. Having first results while working on a task like that, it is good to move back and experiment with choosen parameters. As it is almost impossible to guess optimal parameters on our own, it helps to improve quality of our model's significantly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
